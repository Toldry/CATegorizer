{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CATegorizer",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toldry/CATegorizer/blob/main/CATegorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lkczg1RU9pZ"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ4pWSJAeq_4"
      },
      "source": [
        "We are Alon Eitan and Dor Daniel, students in the Open University of Israel.\n",
        "\n",
        "In this project, we aim to create an image classification model for cat subreddits in the social media website Reddit.\n",
        "\n",
        "Since we both never had a project with computer vision and we thought that this project is a great opportunity try somting new, plus Alon's love for cats and reddit and cats on reddit was unparalleled. His affection won Dor over so we decided to try to classify as many subreddit as posibile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sRna0V_UUtD"
      },
      "source": [
        "##The problem\n",
        "\n",
        " Reddit is a social media platform ,and its structure is a network of communities on people's interests. \n",
        "Its main use is sharing content for the people to see on a subreddits.\n",
        "\n",
        "A subreddit is a specific online community that focuses on a topic, like cars , sports, coding problems and in our case: cats or onlyhappycats or CatsWithHats and even HistoricalCatLovers.\n",
        "\n",
        "Our objective is to create a model that gets a picture of a cat as input, and outputs which subreddit(s) the picture fits the best. \n",
        "\n",
        "For example, if the model receives a picture of a [black cat wearing a hat](https://i.redd.it/f0brl1wvs6v51.jpg), then it may suggest that the picture fits in r/BlackCats and r/CatsWithHats.\n",
        "\n",
        "Then, after the model is complete, we'll create a bot u/CATegorizer_bot, that automatically replies to cat pictures and gives suggestions to which cat subreddits it might fit best.\n",
        "\n",
        "We know that our data set is too broad but still we want to try and see what can we do with it and what unexpected results we can discover. \n",
        "\n",
        "We plan to try a different ways to so, some of them include the libraries TensorFlow,Keras and ImageAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCSd-Lmve27y"
      },
      "source": [
        "# Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHxEwi4e6Dp"
      },
      "source": [
        "## Intersectionality\n",
        "There is a large intersection between the content that can be found in different subreddits. For instance, [this picture](https://i.redd.it/0cj4wyr1uc851.jpg) could be appropriately placed in any one of these subreddits:\n",
        "\n",
        "\n",
        "* r/CatsOnKeyboards\n",
        "* r/IllegallySmolCats\n",
        "* r/tinyorangekittens\n",
        "* r/Catswithjobs\n",
        "* r/orangecats\n",
        "* r/gingerkitty\n",
        "* r/Cats\n",
        "\n",
        "with the last subreddit r/Cats being truly all-encompassing.\n",
        "\n",
        "It is therefore challenging to determine whether any particular picture not only fits a certain subreddit at all, but which of the subreddits that it does fit, are **most** fitting.\n",
        "\n",
        "\n",
        "## Unrelated content\n",
        "Despite reddit being neatly organized into different subreddits, each having a category of content that intuitively fits it, redditors often err and share content to a subreddit that doesn't strictly fit it's theme.\n",
        "\n",
        "Other redditors who like the submission often choose to upvote it despite not fitting the theme of the subreddit, either because they didn't notice the mismatch or they simply don't care.\n",
        "\n",
        "As a result, we find pictures of orange cats in r/BlackCats. This essentialy acts as mislabeled data for the purposes of our classification algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a6cEIrFU0cq"
      },
      "source": [
        "#Data collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fqQrVu8UjWT"
      },
      "source": [
        "To collect the data, we wrote a scraper:\n",
        "https://github.com/Toldry/CATegorizer/blob/main/scraper.py\n",
        "\n",
        "It uses the Python library `praw`, to scans the top 1000 submissions of every cat subreddit.\n",
        "\n",
        "The list `cat_subredditss.csv` was generated from the cat subreddit index:\n",
        "https://www.reddit.com/r/Catsubs/wiki/index\n",
        "\n",
        "\n",
        "The scraper first filtered the subreddits that are restricted or private or deleted, or had too few subscribers. The viable subreddits are in `filtered_cat_subs.csv`.\n",
        "\n",
        "Each submission has many attributes related to it, most of which are irrelevant to our aim of classifying cat images. \n",
        "We arbitrarily chose the following attributes which we thought might be useful:\n",
        "* id\n",
        "* url\n",
        "* permalink\n",
        "* score\n",
        "* title\n",
        "* total_awards_received\n",
        "* ups\n",
        "* upvote_ratio\n",
        "* is_original_content\n",
        "* gilded\n",
        "* num_comments\n",
        "* num_crossposts\n",
        "* num_duplicates\n",
        "* over_18\n",
        "\n",
        "The critical fields are `url` which links to the image, and `score` which shows how many people upvoted the submission.\n",
        "\n",
        "The total number of submission we originally collected is 124,623. \n",
        "\n",
        "The scraper took roughly five days to collect all the data, not including the images themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSF1bIKEUu6o"
      },
      "source": [
        "#Data cleanining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-wVPcuFVHLf"
      },
      "source": [
        "First we discarded all the posts with broken urls.\n",
        "We leveraged the `concurrent.futures` multithreading library to accelrate the process of checking which urls are broken.\n",
        "\n",
        "Without it it would have taken approximately 2 days to run, with it, it ran for only 4~5 hours.\n",
        "Because the time to run was unknown we didnt run it in the notebook.\n",
        "\n",
        "We exported the information of the broken urls to a .txt file so we could check some of the urls to see if they are broken before deleting them. \n",
        "\n",
        "We used 10 seconds for timeouts, luckily no timeouts occured.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNKE3YWCSZ67"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import concurrent.futures\n",
        "import urllib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLMXnUdWSdVS"
      },
      "source": [
        "# def bad_url(a_url, an_index, timeout=10):\n",
        "#     response = requests.get(url=a_url, timeout=timeout)\n",
        "#     if response.status_code == 404:\n",
        "#         #the plus 2 is for maching the index in df to the CSV file for easier confirmation\n",
        "#         print(an_index + 2, 'ERROR')\n",
        "#         return str(an_index + 2)\n",
        "#     #the prining is for following the run\n",
        "#     if (an_index % 2000 == 0 ):\n",
        "#         print(an_index, ' done')\n",
        "#     #when we returned noting or \"\" it bugd out\n",
        "#     return \" \"\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     f = open(\"broken_url.txt\", \"a\",encoding=\"utf-8\")\n",
        "#     df = pd.read_csv('submission.csv')\n",
        "\n",
        "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "#         futures = []\n",
        "#         for x in df.index:\n",
        "#             futures.append(executor.submit(bad_url, a_url=df.loc[x, \"url\"], an_index=x))\n",
        "#         #run on completed Threads output\n",
        "#         for future in concurrent.futures.as_completed(futures):\n",
        "#             try:\n",
        "#                 f.write(future.result())\n",
        "#             except requests.ConnectTimeout:\n",
        "#                 print(\"ConnectTimeout.\")\n",
        "#     f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04JOtvUVdLT"
      },
      "source": [
        "in total, 528 broken urls were detected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qX496PfiYJz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0krOnMZ2psx"
      },
      "source": [
        "#Exploratory data analaysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gat4jMo6B0SM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [20, 10] # Increase the figure size across the entire notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "giTfD_Ic2ukH",
        "outputId": "689b665f-1315-481a-d496-89eae83d1bc8"
      },
      "source": [
        "# Get the data\n",
        "\n",
        "SUBMISSIONS_URL = 'https://raw.githubusercontent.com/Toldry/CATegorizer/main/submission.csv'\n",
        "data = pd.read_csv(SUBMISSIONS_URL)\n",
        "data = data.set_index('id')\n",
        "\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>total_awards_received</th>\n",
              "      <th>ups</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>gilded</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>num_crossposts</th>\n",
              "      <th>num_duplicates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "      <td>125078.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1169.404636</td>\n",
              "      <td>0.701099</td>\n",
              "      <td>1169.404636</td>\n",
              "      <td>0.980533</td>\n",
              "      <td>0.014983</td>\n",
              "      <td>13.913110</td>\n",
              "      <td>0.223349</td>\n",
              "      <td>0.465150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2568.936052</td>\n",
              "      <td>5.259843</td>\n",
              "      <td>2568.936052</td>\n",
              "      <td>0.042288</td>\n",
              "      <td>0.140240</td>\n",
              "      <td>35.995101</td>\n",
              "      <td>0.870128</td>\n",
              "      <td>1.663655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>277.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>277.000000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>982.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>982.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>71658.000000</td>\n",
              "      <td>522.000000</td>\n",
              "      <td>71658.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>4054.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>51.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               score  total_awards_received  ...  num_crossposts  num_duplicates\n",
              "count  125078.000000          125078.000000  ...   125078.000000   125078.000000\n",
              "mean     1169.404636               0.701099  ...        0.223349        0.465150\n",
              "std      2568.936052               5.259843  ...        0.870128        1.663655\n",
              "min         0.000000               0.000000  ...        0.000000        0.000000\n",
              "25%        77.000000               0.000000  ...        0.000000        0.000000\n",
              "50%       277.000000               0.000000  ...        0.000000        0.000000\n",
              "75%       982.000000               0.000000  ...        0.000000        0.000000\n",
              "max     71658.000000             522.000000  ...       27.000000       51.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccsM-soy4W5a",
        "outputId": "d43cd92d-83cf-4a5f-ede7-6b98c047d86e"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['subreddit_name', 'url', 'permalink', 'score', 'title',\n",
              "       'total_awards_received', 'ups', 'upvote_ratio', 'is_original_content',\n",
              "       'gilded', 'num_comments', 'num_crossposts', 'num_duplicates',\n",
              "       'over_18'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWIvV8aS8bpI",
        "outputId": "aaeb431e-b27a-4f58-dd25-533b84d452fa"
      },
      "source": [
        "# Number of different subreddits:\n",
        "len(data['subreddit_name'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "346"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGYSSpa95YpW"
      },
      "source": [
        "We'd also be wise to filter out any submission that doesn't have some minimum number of upvotes, because such submissions are less likely to be reliably relevant to their respective subreddit, or be relevant at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKX3q4Or54zI",
        "outputId": "64fc8afb-9c68-4718-daa1-3d99d155c042"
      },
      "source": [
        "MINIMUM_SCORE_THRESHOLD = 100\n",
        "score_below_minimum = data['score'] < MINIMUM_SCORE_THRESHOLD\n",
        "print(score_below_minimum.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False    88158\n",
            "True     36920\n",
            "Name: score, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F2wXo91CJIN"
      },
      "source": [
        "The most important value we can use to judge how \"good\" or \"fitting the subreddit\" a single submission is by looking at the number of **upvotes** it has.\n",
        "\n",
        "In the dataset, this info is in the `score` column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "IeCyeo2q9i9v",
        "outputId": "8d3a47b9-d6cb-4fd4-852e-30b5bff99578"
      },
      "source": [
        "grouped = data.groupby('subreddit_name')\n",
        "result = grouped.agg({'score': ['mean', 'min', 'max']})\n",
        "result = result.sort_values(('score', 'max'), ascending=False)\n",
        "result['score']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subreddit_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cats</th>\n",
              "      <td>19493.501269</td>\n",
              "      <td>15038</td>\n",
              "      <td>71658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chonkers</th>\n",
              "      <td>10951.398252</td>\n",
              "      <td>6416</td>\n",
              "      <td>48697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Meow_Irl</th>\n",
              "      <td>10433.070857</td>\n",
              "      <td>6923</td>\n",
              "      <td>34105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatsWhoYell</th>\n",
              "      <td>10596.463710</td>\n",
              "      <td>5831</td>\n",
              "      <td>33759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StartledCats</th>\n",
              "      <td>12587.205882</td>\n",
              "      <td>7307</td>\n",
              "      <td>29284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatQueries</th>\n",
              "      <td>3.428571</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FelineCare</th>\n",
              "      <td>3.550000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatsFailingJumps</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CatsStuckInThings</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cathletes</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>346 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           mean    min    max\n",
              "subreddit_name                               \n",
              "Cats               19493.501269  15038  71658\n",
              "Chonkers           10951.398252   6416  48697\n",
              "Meow_Irl           10433.070857   6923  34105\n",
              "CatsWhoYell        10596.463710   5831  33759\n",
              "StartledCats       12587.205882   7307  29284\n",
              "...                         ...    ...    ...\n",
              "CatQueries             3.428571      0      9\n",
              "FelineCare             3.550000      1      6\n",
              "CatsFailingJumps       6.000000      6      6\n",
              "CatsStuckInThings      3.500000      1      6\n",
              "Cathletes              4.000000      4      4\n",
              "\n",
              "[346 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ub2TTu4CuHa"
      },
      "source": [
        "Let's take a look at the number of upvotes each subreddit's most upvoted submission has:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "XGxQXbJf_7jQ",
        "outputId": "3c431787-7ce6-4df2-dadf-d251c0fbd5b4"
      },
      "source": [
        "result2 = result[('score', 'max')]\n",
        "result2 = result['score']['max']\n",
        "result2.hist(bins=50)\n",
        "plt.axvline(5000, color='r', linewidth=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7efc60b91b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uHeXFGxChZZ"
      },
      "source": [
        "The vast majority of subreddit's most upvoted submission has a score that is below 5000. (Left of the red line)\n",
        "\n",
        "Let's take a more granular look at those subreddits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "XNEXTcdoDoz4",
        "outputId": "1ee7bbd6-d32f-480c-a9a4-a9880dc61469"
      },
      "source": [
        "result3 = result2[result2 < 5000]\n",
        "result3.hist(bins=40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7efc60e0c590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t67EIKztGNgl"
      },
      "source": [
        "When the top submission has fewer than 1000 upvotes, it indicates that the subreddit is not very popular. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dmJu-JSGBwh",
        "outputId": "f0ef4933-2bc0-4077-cbd4-b8f60a49ad38"
      },
      "source": [
        "SUBREDDIT_MINIMUM_SCORE_THRESHOLD = 1000\n",
        "\n",
        "subreddits_below_minimum_threshold = result2 < SUBREDDIT_MINIMUM_SCORE_THRESHOLD\n",
        "\n",
        "print(subreddits_below_minimum_threshold.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True     248\n",
            "False     98\n",
            "Name: max, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DySVlCmBJUTJ"
      },
      "source": [
        "## Numerical fields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "N0eAdEkPJTsY",
        "outputId": "7fab1f3c-68fc-445c-d660-697b1880ca83"
      },
      "source": [
        "numerical_classes = ['score', 'total_awards_received', 'ups', 'upvote_ratio', 'gilded', 'num_comments', 'num_crossposts', 'num_duplicates']\n",
        "df2 = data[numerical_classes]\n",
        "normalized = ((df2 - df2.mean()) / df2.std())\n",
        "normalized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>total_awards_received</th>\n",
              "      <th>ups</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>gilded</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>num_crossposts</th>\n",
              "      <th>num_duplicates</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kodzf7</th>\n",
              "      <td>-0.292107</td>\n",
              "      <td>0.056827</td>\n",
              "      <td>-0.292107</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>0.446919</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lwk2qq</th>\n",
              "      <td>-0.328698</td>\n",
              "      <td>0.056827</td>\n",
              "      <td>-0.328698</td>\n",
              "      <td>0.223875</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.080931</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clcd2p</th>\n",
              "      <td>-0.344658</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.344658</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.275402</td>\n",
              "      <td>0.892572</td>\n",
              "      <td>0.321491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goit9q</th>\n",
              "      <td>-0.350886</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.350886</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.247620</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>0.321491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kxctgx</th>\n",
              "      <td>-0.354390</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.354390</td>\n",
              "      <td>0.223875</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.247620</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pdaon</th>\n",
              "      <td>-0.452096</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.452096</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.358746</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>0.321491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pda5i</th>\n",
              "      <td>-0.452096</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.452096</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.386528</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pkxou</th>\n",
              "      <td>-0.452096</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.452096</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.386528</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5l1ole</th>\n",
              "      <td>-0.453263</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.453263</td>\n",
              "      <td>0.460346</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.386528</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poika</th>\n",
              "      <td>-0.453653</td>\n",
              "      <td>-0.133293</td>\n",
              "      <td>-0.453653</td>\n",
              "      <td>-3.323201</td>\n",
              "      <td>-0.106836</td>\n",
              "      <td>-0.386528</td>\n",
              "      <td>-0.256685</td>\n",
              "      <td>-0.279595</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>125078 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           score  total_awards_received  ...  num_crossposts  num_duplicates\n",
              "id                                       ...                                \n",
              "kodzf7 -0.292107               0.056827  ...       -0.256685       -0.279595\n",
              "lwk2qq -0.328698               0.056827  ...       -0.256685       -0.279595\n",
              "clcd2p -0.344658              -0.133293  ...        0.892572        0.321491\n",
              "goit9q -0.350886              -0.133293  ...       -0.256685        0.321491\n",
              "kxctgx -0.354390              -0.133293  ...       -0.256685       -0.279595\n",
              "...          ...                    ...  ...             ...             ...\n",
              "pdaon  -0.452096              -0.133293  ...       -0.256685        0.321491\n",
              "pda5i  -0.452096              -0.133293  ...       -0.256685       -0.279595\n",
              "pkxou  -0.452096              -0.133293  ...       -0.256685       -0.279595\n",
              "5l1ole -0.453263              -0.133293  ...       -0.256685       -0.279595\n",
              "poika  -0.453653              -0.133293  ...       -0.256685       -0.279595\n",
              "\n",
              "[125078 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQvojUuLo7q"
      },
      "source": [
        "# This takes a long time (> 2 min) to execute\n",
        "#pd.plotting.scatter_matrix(normalized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qF0mq91KzJ7"
      },
      "source": [
        "import seaborn as sns\n",
        "# This takes a long time (>13 min) to execute\n",
        "# sns.heatmap(normalized, cmap=\"YlGnBu\", annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzQBG0ZVN5E-"
      },
      "source": [
        "##Binary Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXgRqgGUP_xl"
      },
      "source": [
        "The dataset includes only two binary fields: `is_original_content` and `over_18`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXPlu289N6-E",
        "outputId": "e49734cb-76e1-4a4e-9ead-a4867423bd37"
      },
      "source": [
        "print(data['is_original_content'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False    124857\n",
            "True        221\n",
            "Name: is_original_content, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNhoGbw0OU1V"
      },
      "source": [
        "It well known by redditors that the majority of the posts in reddit are reposts, meaning that they are not original content.\n",
        "\n",
        "However, it is surprisng to see that such a tiny fraction 221/124857 $\\approx$ 0.001 of posts are marked as \"original content\".\n",
        "\n",
        "Upon closer inspection, the `is_original_content` field appears to be [a rarely-used feature accessible only to moderators](https://www.reddit.com/r/redesign/comments/8a48uv/moderators_try_marking_posts_as_oc_on_the_redesign/), which explains why there are so few posts that are marked as OC.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTwkQB54Q_r-",
        "outputId": "96a74a52-51ac-4754-8cb5-b3dd9331120b"
      },
      "source": [
        "print(data['over_18'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False    124287\n",
            "True        791\n",
            "Name: over_18, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DDcyVd1RB7J"
      },
      "source": [
        "The `over_18` flag, also known as the \"NSFW\" flag (not safe for work) is used by both users and moderators to mark content that may contain nudity, intense sexuality, political incorrectness, profanity, slurs, violence or other potentially disturbing subject matter \n",
        "\n",
        "Seeing as our subject matter is cats, it makes sense that very few posts in our data are marked as `over_18`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzoOAJtWTVi6"
      },
      "source": [
        "Since both flags don't contribute almost at all to the data, we can safely drop both of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwvGOdPTf7w"
      },
      "source": [
        "columns_to_remove = ['is_original_content', 'over_18']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxMCeHZvinIA"
      },
      "source": [
        "## Text fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWuhz8MIit11"
      },
      "source": [
        "The only text field in the dataset is `title`.\n",
        "\n",
        "One venue to explore may be to use NLP techniques to extract useful information from title of the submission.\n",
        "\n",
        "For now, we'll look at the simplest feature: length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "lvDdSfmXjfAK",
        "outputId": "7c7cebe7-2bf7-4cf0-aba4-54a075636b85"
      },
      "source": [
        "data['title_len'] = data['title'].str.len()\n",
        "numerical_classes += ['title_len']\n",
        "data['title_len'].hist()\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       subreddit_name                                  url  ... over_18  title_len\n",
            "id                                                          ...                   \n",
            "kodzf7        catsubs  https://i.redd.it/eog5205syq861.jpg  ...   False         53\n",
            "lwk2qq        catsubs  https://i.redd.it/8mcvaqsxfqk61.jpg  ...   False         94\n",
            "clcd2p        catsubs      https://i.imgur.com/427vpjE.jpg  ...   False         19\n",
            "goit9q        catsubs  https://i.redd.it/d20yl18pcb051.jpg  ...   False         32\n",
            "kxctgx        catsubs  https://i.redd.it/qdhnttwqncb61.jpg  ...   False         81\n",
            "...               ...                                  ...  ...     ...        ...\n",
            "pdaon   onlyhappycats         http://i.imgur.com/GbeFh.jpg  ...   False         43\n",
            "pda5i   onlyhappycats         http://i.imgur.com/3BMBI.jpg  ...   False         22\n",
            "pkxou   onlyhappycats         http://i.imgur.com/vwlFr.jpg  ...   False         33\n",
            "5l1ole  onlyhappycats   https://i.redd.it/y2qi5d0t0n6y.jpg  ...   False         41\n",
            "poika   onlyhappycats         http://i.imgur.com/y0hY5.jpg  ...   False         12\n",
            "\n",
            "[125078 rows x 15 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPF_RoPMkczP"
      },
      "source": [
        "Reddit's 300 character limit is apparent from this graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX1hMFOxzEGk"
      },
      "source": [
        "##Other Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzVBKIR8zbQT"
      },
      "source": [
        "`score` and `ups` are the same field:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKuwiigO0GHp",
        "outputId": "e6ff7523-b8c7-4048-868b-b01796e8e6a6"
      },
      "source": [
        "(data['score'] - data['ups']).value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    125078\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNZ3GjpjO7z"
      },
      "source": [
        "Therefore we can drop the `ups` field."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i178Q1CIjUBD"
      },
      "source": [
        "columns_to_remove += ['ups']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGNtmLqp0TnF"
      },
      "source": [
        "`upvote_ratio` is a field that was used in the past , reddit decided to stop using it without official information \n",
        "https://www.reddit.com/r/Enhancement/wiki/faq/uppers_downers_removed\n",
        "\n",
        "`gilded` and `total_awards_received` are both bought with money , and they could be exploited. \n",
        "we could not find any relevent information frome both of them.\n",
        "\n",
        "we belive that the fields `num_comments`,`num_crossposts`,`num_duplicates` may have some correlation to the success chance of the model so we will check it in the future "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltocsctWoifH"
      },
      "source": [
        "##Principal Component Analaysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8n44rUJkoTB"
      },
      "source": [
        "###Alon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LxBZ6V9kpTJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "64d703b2-07c5-4fae-c75e-dd1ed4566763"
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "import pathlib\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=6)\n",
        "\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "targets = []\n",
        "images = []\n",
        "\n",
        "#github test\n",
        "\n",
        "for filename in glob.glob('images/*'):\n",
        "  subreddit = pathlib.PurePath(filename).name\n",
        "  for imfile in glob.glob(filename + '/*.*'):\n",
        "    img = cv2.imread(imfile)\n",
        "    try:\n",
        "      res = cv2.resize(img, dsize=(img_height, img_width), interpolation=cv2.INTER_CUBIC)\n",
        "    except:\n",
        "      continue\n",
        "    res = np.array(res).flatten()\n",
        "    res = res/255\n",
        "    images += [res]\n",
        "    targets += [subreddit]\n",
        "\n",
        "\n",
        "\n",
        "pca = PCA(2)  # project from 64 to 2 dimensions\n",
        "projected = pca.fit_transform(images)\n",
        "\n",
        "colors = []\n",
        "color_map = {'BattleCats': 'red', 'SphynxCats': 'yellow', 'blackcats': 'black', 'TardCat': 'purple'}\n",
        "for t in targets:\n",
        "  colors += [color_map[t]]\n",
        "\n",
        "# projected = projected[0:10]\n",
        "# colors = colors[0:10]\n",
        "\n",
        "print(projected)\n",
        "print(colors)\n",
        "\n",
        "plt.scatter(projected[:, 0], projected[:, 1],\n",
        "            c=colors, edgecolor='none', alpha=0.5)\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-55cd012b74bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# project from 64 to 2 dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprojected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 391\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWOvBKSwwFIt"
      },
      "source": [
        "**לסיים לנסות להריץ את הדומא של דור ובתקווה להשוות בין התוצעות במקרה ולא עובד למחוק**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMSJC5kyqTMO"
      },
      "source": [
        "#https://medium.com/@sebastiannorena/pca-principal-components-analysis-applied-to-images-of-faces-d2fc2c083371\n",
        "dor_frame = pd.DataFrame(images)\n",
        "\n",
        "fig, axes = plt.subplots(10,10,figsize=(9,9),\n",
        " subplot_kw={'xticks':[], 'yticks':[]},\n",
        " gridspec_kw=dict(hspace=0.01, wspace=0.01))\n",
        "for i, ax in enumerate(axes.flat):\n",
        " ax.imshow(dor_frame.iloc[i].values.reshape(180,180),cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZjKGZZWv4py"
      },
      "source": [
        "rom sklearn.decomposition import PCA\n",
        "#n_components=0.80 means it will return the Eigenvectors that have the 80% of the variation in the dataset\n",
        "faces_pca = PCA(n_components=0.8)\n",
        "faces_pca.fit(faces)\n",
        "fig, axes = plt.subplots(2,10,figsize=(9,3),\n",
        " subplot_kw={‘xticks’:[], ‘yticks’:[]},\n",
        " gridspec_kw=dict(hspace=0.01, wspace=0.01))\n",
        "for i, ax in enumerate(axes.flat):\n",
        " ax.imshow(dor_frame.components_[i].reshape(112,92),cmap=”gray”)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPMBmwJVwebx"
      },
      "source": [
        "components = faces_pca.transform(dor_frame)\n",
        "projected = faces_pca.inverse_transform(components)\n",
        "fig, axes = plt.subplots(10,10,figsize=(9,9), subplot_kw={'xticks':[], 'yticks':[]},\n",
        "            gridspec_kw=dict(hspace=0.01, wspace=0.01))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(projected[i].reshape(112,92),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgXyxDyTwg0C"
      },
      "source": [
        "**סוף דוגמא של דור לא לשכוח לשנות שמות של פנים לחתולים**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoPtPyJwon4A"
      },
      "source": [
        "df2 = data[numerical_classes]\n",
        "print(numerical_classes)\n",
        "normalized = ((df2 - df2.mean()) / df2.std())\n",
        "normalized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APgWyxxKvVs3"
      },
      "source": [
        "#Code example taken from https://www.datasklr.com/principal-component-analysis-and-factor-analysis/principal-component-analysis\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=6)\n",
        "Principal_components=pca.fit_transform(normalized)\n",
        "pca_df = pd.DataFrame(data = Principal_components, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6'])\n",
        "print(pca.components_)\n",
        "print('#'*90)\n",
        "print(pca.explained_variance_)\n",
        "print('#'*90)\n",
        "print(pca_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZbJ07QBvbpF"
      },
      "source": [
        "# Reset index necessary for the concat to work with the same shaped datasets\n",
        "pca_df.reset_index(drop=True, inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "for_visual = pd.concat([pca_df, data['subreddit_name']], axis = 1)\n",
        "print(for_visual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF40EyGayUXp"
      },
      "source": [
        "#for_visual = for_visual.groupby('subreddit_name').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UaFSgYRv3OI"
      },
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.add_subplot(1,1,1) \n",
        "ax.set_xlabel('PC 1', fontsize = 15)\n",
        "ax.set_ylabel('PC 2', fontsize = 15)\n",
        "ax.set_title('Plot of 1st Two Principal Components vs. Subreddit', fontsize = 20)\n",
        "W_GROUP = ['1st 33%','2nd 33%','3rd 33%']\n",
        "colors = ['navy', 'turquoise', 'darkorange']\n",
        "# for WINS_GROUP, color in zip(W_GROUP,colors):\n",
        "#     indicesToKeep = for_visual['WINS_GROUP'] == WINS_GROUP\n",
        "#     ax.scatter(for_visual.loc[indicesToKeep, 'PC 1']\n",
        "#                , for_visual.loc[indicesToKeep, 'PC 2']\n",
        "#                , c = color\n",
        "#                , s = 50)\n",
        "ax.scatter(for_visual.loc[:, 'PC 1']\n",
        "            , for_visual.loc[:, 'PC 2']\n",
        "            , s = 50)\n",
        "# ax.legend(W_GROUP)\n",
        "ax.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoPfo5yazF87"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "PC_values = np.arange(pca.n_components_) + 1\n",
        "plt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Proportion of Variance Explained')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mRENWLjzaav"
      },
      "source": [
        "The \"elbow\" of the plot is clearly at $n=2$ principal components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tjmO9AXLfjl"
      },
      "source": [
        "### Image PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqkob7VLLkdY"
      },
      "source": [
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import asarray\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "data_dir = cwd + '/images'\n",
        "\n",
        "#image_list = pd.DataFrame([])\n",
        "image_list = []\n",
        "image_suffixes = ['png', 'jpg', 'jpeg']\n",
        "\n",
        "\n",
        "i = 0\n",
        "for filename in glob.glob(data_dir + '/*/*.*'): \n",
        "    im=cv.imread(filename)\n",
        "    try:\n",
        "      cat = pd.Series(im.flatten(),name=filename)\n",
        "    except:\n",
        "      continue\n",
        "    image_list.append(cat)\n",
        "    i+=1\n",
        "    if i==1000: break\n",
        "\n",
        "image_fream=pd.DataFrame(image_list)\n",
        "\n",
        "fig, axes = plt.subplots(10,10,figsize=(9,9),\n",
        " subplot_kw={'xticks':[], 'yticks':[]},\n",
        " gridspec_kw=dict(hspace=0.01, wspace=0.01))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  print(image_list,i)\n",
        "  ax.imshow(image_fream.iloc[i].values.reshape(112,92))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDt2lmXVR_MM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJ8eM2cP073"
      },
      "source": [
        "# Filteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ4QNoHTP314"
      },
      "source": [
        "We filter the following rows:\n",
        "* Duplicates\n",
        "* Broken urls\n",
        "* Score below minimum threshold (`score_below_minimum`)\n",
        "* Submissions belonging to subreddits with top post which has a score below minmum threshold (`subreddits_below_minimum_threshold`)\n",
        "\n",
        "and the following columns:\n",
        "* is_original_content\n",
        "* over_18\n",
        "* upvote_ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezoS2LxQLbh"
      },
      "source": [
        "#after resting index set it again\n",
        "data = pd.read_csv(SUBMISSIONS_URL)\n",
        "data = data.set_index('id')\n",
        "data3 = data.drop_duplicates()\n",
        "print(f'Duplicates removed: {len(data) - len(data3)}')\n",
        "\n",
        "index_to_delete = []\n",
        "BROKEN_URLS = 'https://raw.githubusercontent.com/Toldry/CATegorizer/main/broken_url_by_id.txt'\n",
        "with urllib.request.urlopen(BROKEN_URLS) as file:\n",
        "  for line in file:\n",
        "    decoded_line = line.decode('utf-8')\n",
        "    decoded_line = decoded_line[0:-1] # remove newline\n",
        "    index_to_delete += [decoded_line]\n",
        "\n",
        "print(data)\n",
        "data4 = data3.drop(index_to_delete)\n",
        "print(f'Broken url rows removed: {len(data3)- len(data4)}')\n",
        "\n",
        "\n",
        "data5 = data4.drop((data4[data4['score'] < MINIMUM_SCORE_THRESHOLD]).index)\n",
        "print(f'Score below minimum threshold rows removed: {len(data4)- len(data5)}')\n",
        "\n",
        "\n",
        "subreddits_to_delete = list(subreddits_below_minimum_threshold[subreddits_below_minimum_threshold == True].index)\n",
        "data6 = data5.drop(data5[data5['subreddit_name'].isin(subreddits_to_delete)].index)\n",
        "\n",
        "print(f'Subreddit below minimum threshold, rows removed: {len(data5)- len(data6)}')\n",
        "len(data6)\n",
        "\n",
        "data7 = data6.drop(columns=columns_to_remove)\n",
        "print(f'Dropped columns: {str(columns_to_remove)}')\n",
        "\n",
        "filtered_data = data7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOJ0Kbkn-r3P"
      },
      "source": [
        "#Save filtered data to csv\n",
        "filtered_data.to_csv('filtered_submissions.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSndUDm6lpP9"
      },
      "source": [
        "# Downloading the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq6CKcRosT67"
      },
      "source": [
        "We download the images form the URLs into \"images\" file, and then we separated them into \"train\" and \"test\" files,they will be used in the futere like with working with ImageAi \n",
        "we decided arbitrarily on 20% split. \n",
        "in the futere this parameter will probably have big impact on the results.\n",
        "we decided on a percentage type parameter instead on a fixed one becuse not all subredits have the same amount of submissions.\n",
        "\n",
        "For the Project proposal we decided on 2 subreddits to save on run time. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVOGyPzflqgX"
      },
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "cwd = os.getcwd()\n",
        "print(cwd)\n",
        "\n",
        "p = Path(cwd + '/images')\n",
        "p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "subreddits = ['blackcats', 'SphynxCats']\n",
        "\n",
        "\n",
        "import re\n",
        "image_suffixes = ['png', 'jpg', 'jpeg']\n",
        "image_rx = re.compile('.*\\.(' + '|'.join([f'{str}' for str in image_suffixes]) + ')$')\n",
        "\n",
        "import urllib\n",
        "for sub in subreddits:\n",
        "  sub_path = Path(cwd + '/images/' + sub)\n",
        "  sub_path.mkdir(parents=True, exist_ok=True)\n",
        "  submissions = filtered_data[filtered_data['subreddit_name'].str.lower() == sub.lower()]\n",
        "  for index, row in submissions.iterrows():\n",
        "    url = row['url']\n",
        "    id = index\n",
        "    suffix = image_rx.match(url).groups()[0]\n",
        "    image_path = str(sub_path) +'/' + id + '.' + suffix\n",
        "    try:\n",
        "      urllib.request.urlretrieve(url, image_path)\n",
        "    except:\n",
        "      pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5myBIuh5HZq"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "SPLIT_PERCENTAGE = 0.2\n",
        "\n",
        "p2 = Path(cwd + '/images2')\n",
        "p2.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "for sub in subreddits:\n",
        "  random.seed(1)\n",
        "  sub_path1 = Path(cwd + '/images/' + sub)\n",
        "  sub_path2 = Path(cwd + '/images2/' + sub)\n",
        "  sub_path2.mkdir(parents=True, exist_ok=True)\n",
        "  files = os.listdir(sub_path1)\n",
        "  random.shuffle(files)\n",
        "  num_files = len(files)\n",
        "  split_point = math.floor(num_files * SPLIT_PERCENTAGE)\n",
        "  test = files[:split_point]\n",
        "  train = files[split_point+1:]\n",
        "  print(f'Num test files in sub {sub}: {len(test)}')\n",
        "  print(f'Num train files in sub {sub}: {len(train)}')\n",
        "  test_folder_path = str(sub_path2) + '/test'\n",
        "  train_folder_path = str(sub_path2) + '/train'\n",
        "  Path(test_folder_path).mkdir(parents=True, exist_ok=True)\n",
        "  Path(train_folder_path).mkdir(parents=True, exist_ok=True)\n",
        "  for f in test:\n",
        "    image_soruce_path = str(sub_path1) + '/' + f\n",
        "    image_target_path = test_folder_path + '/' + f\n",
        "    shutil.copy(image_soruce_path, image_target_path)\n",
        "  for f in train:\n",
        "    image_soruce_path = str(sub_path1) + '/' + f\n",
        "    image_target_path = train_folder_path + '/' + f\n",
        "    shutil.copy(image_soruce_path, image_target_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROB_CRXJvhXo"
      },
      "source": [
        "## Downloading from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LSh1bQOvixB"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')\n",
        "\n",
        "# # Import PyDrive and associated libraries.\n",
        "# # This only needs to be done once per notebook.\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKxYR1jBxg5X"
      },
      "source": [
        "# images_path= '/gdrive/MyDrive/Academic/Data Science Workshop/CATegorizer/images'\n",
        "# # images_path= '/gdrive/'\n",
        "\n",
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# onlyfiles = [f for f in listdir(images_path) if isfile(join(images_path, f))]\n",
        "# import glob\n",
        "# print(glob.glob(images_path + '/**'))\n",
        "# print('done')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTM_h1puz29v"
      },
      "source": [
        "# import os\n",
        "# from pathlib import Path\n",
        "# cwd = os.getcwd()\n",
        "\n",
        "# p = Path(cwd + '/images')\n",
        "# p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# images_path= '/gdrive/MyDrive/Academic/Data Science Workshop/CATegorizer/images'\n",
        "# images_folder_id = '15PAXlY2jk3uSQuOAnufTAdKz8eeIFzqv'\n",
        "\n",
        "\n",
        "# images_folder = drive.ListFile({'q': f\"'{images_folder_id}' in parents and trashed=false\"}).GetList()\n",
        "# for cat_images_folder in images_folder:\n",
        "#   # print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "#   inner_file_list = drive.ListFile({'q': f\"'{cat_images_folder['id']}' in parents and trashed=false\"}).GetList()\n",
        "#   sub_path = Path(str(p) + '/' + cat_images_folder['title'])\n",
        "#   sub_path.mkdir(parents=True, exist_ok=True)\n",
        "#   for image_file in inner_file_list:\n",
        "#     print('title: %s, id: %s' % (image_file['title'], image_file['id']))\n",
        "#     image_path = Path(str(sub_path) + '/' + image_file['title'])\n",
        "#     downloaded = drive.CreateFile({'id': image_file['id']})\n",
        "#     downloaded.GetContentFile(str(image_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jzkmMzV4B9a"
      },
      "source": [
        "# file_id = '14vo80bdz30qzU8Dgkx4eDLNzS3EdlCAj'\n",
        "# downloaded = drive.CreateFile({'id': file_id})\n",
        "# # print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "# downloaded.GetContentFile('bla/catlove.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZRyOZM21oKg"
      },
      "source": [
        "# Image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkrS6phi2Gbg"
      },
      "source": [
        "we kept the same split percentage. and Define the loading parameters for using keras. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xanJJEpIqUQK"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "\n",
        "data_dir = Path(cwd + '/images2')\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLTbiXlZA9C6"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRPcjTW0BTGm"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KADRRDuL4M0w"
      },
      "source": [
        "Here are the first 9 images from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbYFwKNTBU_y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(train_ds)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SeVvMb-52h4"
      },
      "source": [
        "loading the data in order to increase performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27S1iiBECCob"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o4wXCWy6OJ4"
      },
      "source": [
        "standardize the values of the image pixels using map to be in the [0, 1] range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh4fZp_hCOXC"
      },
      "source": [
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tby-DfgmCc3Z"
      },
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsVzFFXl64mQ"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBo8pEk_CzDN"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3jXi8Aw7Zdo"
      },
      "source": [
        "for now we gona try the adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trZeFajwC1s4"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keeNsGDuC3J6"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqWSJzTZ7-JX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J5UFEEJC7qR"
      },
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ErotilADASS"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMTDWVq-8N44"
      },
      "source": [
        "after Visualizing the results we can see thet the training accuracy and validation accuracy are off by large margin and the model has achieved  around 80% accuracy on the validation set.\n",
        "\n",
        "we still need to keep in mind that the model only ran on 2 subreddits\n",
        "\n",
        "in the plots, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 80%-85% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujDDoM20-gxx"
      },
      "source": [
        "##Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7gB6MSm--mZ"
      },
      "source": [
        "we do it to boost the number of available training pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZredSKhM-kT_"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=(img_height, \n",
        "                                                              img_width,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpOCw12g-z0X"
      },
      "source": [
        "vivisualizing the augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OZeqjLY-1ff"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l3NgUgH_c0f"
      },
      "source": [
        "## Retrying with augmented data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDYLH2FE_lGm"
      },
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMKIW7bH_oaW"
      },
      "source": [
        "compile and train again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vYLsHpS_rVm"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxPH31hg_t1X"
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZqlFagW_zoW"
      },
      "source": [
        "acc_after_augmentation = history.history['accuracy']\n",
        "val_acc_after_augmentation = history.history['val_accuracy']\n",
        "\n",
        "loss_after_augmentation = history.history['loss']\n",
        "val_loss_after_augmentation = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.plot(epochs_range, acc_after_augmentation, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc_after_augmentation, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.plot(epochs_range, loss_after_augmentation, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss_after_augmentation, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh0-VbP9rtj5"
      },
      "source": [
        "Before the data augmentation, the model yielded a validation accuracy of 0.8, and after the data augmentation, it remained at around 0.8.\n",
        "\n",
        "However, the validation loss decreased from 1 to 0.35\n",
        "\n",
        "also the training also the training lost increases from almost zero to 0.25 \n",
        "\n",
        "Notice how the data augmentation did not improve the validation accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwgXVxr2_7D_"
      },
      "source": [
        "Finally, let's use our model to classify an image that wasn't included in the training or validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGABfKg4_-sn"
      },
      "source": [
        "cat_url = \"https://upload.wikimedia.org/wikipedia/commons/e/e8/Sphinx2_July_2006.jpg\"\n",
        "cat_path = tf.keras.utils.get_file('wikipedia_sphynx_cat', origin=cat_url)\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    cat_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTD46qBNAxZt"
      },
      "source": [
        "cat1_url = \"https://upload.wikimedia.org/wikipedia/commons/e/e8/Sphinx2_July_2006.jpg\"\n",
        "cat2_url = \"https://upload.wikimedia.org/wikipedia/commons/4/4c/Blackcat-Lilith.jpg\"\n",
        "cat1_path = tf.keras.utils.get_file('wikipedia_sphynxcat', origin=cat1_url)\n",
        "cat2_path = tf.keras.utils.get_file('wikipedia_blackcat', origin=cat2_url)\n",
        "\n",
        "img1 = keras.preprocessing.image.load_img(\n",
        "    cat1_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img2 = keras.preprocessing.image.load_img(\n",
        "    cat2_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array1 = keras.preprocessing.image.img_to_array(img1)\n",
        "img_array2 = keras.preprocessing.image.img_to_array(img2)\n",
        "img_array1 = tf.expand_dims(img_array1, 0) # Create a batch\n",
        "img_array2 = tf.expand_dims(img_array2, 0) # Create a batch\n",
        "\n",
        "\n",
        "prediction1 = model.predict(img_array1)\n",
        "prediction2 = model.predict(img_array2)\n",
        "score1 = tf.nn.softmax(prediction1[0])\n",
        "score2 = tf.nn.softmax(prediction2[0])\n",
        "\n",
        "print(\n",
        "    \"Image 1 most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score1)], 100 * np.max(score1))\n",
        ")\n",
        "print(\n",
        "    \"Image 2 most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score2)], 100 * np.max(score2))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HnQwdqZeqF2"
      },
      "source": [
        "As evident from the above cell, the model succesfuly clasified both cats in their respective subreddits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au_hRddN9gkk"
      },
      "source": [
        "#Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsFv6te79iDg"
      },
      "source": [
        "TODO"
      ]
    }
  ]
}